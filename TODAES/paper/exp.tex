\section{EXPERIMENTAL SETTING, RESULTS AND DISCUSSION}
\label{sec:exp}
\subsection{Experimental Setting}
The proposed framework for aging tolerance is implemented in C++ and the SAT-based formulation is solved by MiniSat on a 2.83GHz Intel Quad-Core CPU workstation running Linux. The benchmark circuits are chosen from the IWLS'05 and ISCAS'89 suites. The technology used is TSMC 45nm GP standard cell series.

Under 10-year BTI, the aging rates of clock buffers were obtained from HSPICE. The aging rates of clock buffers with duty cycles of 20\%, 40\%, 50\%, and 80\% are 8.51\%, 12.08\%, 13.51\%, and 16.41\% respectively and the aging rate of logic is obtained by using the predictive model presented in~\cite{wang2010impact, wang2007efficient, gomez2016early, amrouch2016reliability} (detailed in Section~\ref{subsec:apm}).
\input{figures/table_benchmark_info}
\input{figures/table_experiment}
\subsection{Experimental Results}
Table~\ref{table:exp1} and Table~\ref{table:exp2} reports the information of each benchmark and the experimental results. In Table~\ref{table:exp1}, Columns 2 to 5 show the total count of gates, total count of flip-flops, total count of clock buffers, and maximum level of the clock tree in each benchmark respectively. In Table~\ref{table:exp2}, Column 4 to 7 show the results when DCC deployment is considered in the framework. Column 8 to 12 show the results when high-$V_{th}$ assignment for clock buffers is applied on top of DCC deployment.

In Table~\ref{table:exp2}, Column 2  demonstrates the fresh clock period that is the circuit delay without aging, denoted by $T_{c\_fresh}$. Column 3 demonstrates the clock period of the circuit under 10-year aging, denoted by $T_{c\_aged}$. Column 4 and 8 demonstrate the optimized clock period of the circuit under 10-year aging after applying our framework, denoted by $T_{c\_aged\_opt}$. A shorter clock period under aging implies better circuit performance and higher level of aging tolerance. Column 5 and 9 demonstrate the used DCC count. Column 6 and 11 demonstrate the runtime and the Column 7 and 12 demonstrate the improvement, i.e., the level of aging tolerance which is calculated as:
\begin{gather*}
1 - (T_{c\_aged\_opt} - T_{c\_fresh}) / (T_{c\_aged} - T_{c\_fresh})
\end{gather*}
For benchmark \textit{des\_perf}, $T_{c\_fresh}$ is 773.9ps and $T_{c\_aged}$ is 897.8ps, which means after 10-year aging the clock period of circuit will increase by 123.9ps. With DCC insertion using the proposed framework, the clock period achieved is 849.9ps, an increment of 76ps against $T_{c\_fresh}$ (38.66\% improvement). With high-$V_{th}$ assignment applied on top of DCC insertion, the clock period drops to 816.8ps, a smaller increment of 42.9ps against $T_{c\_fresh}$ (65.38\% improvement), implying better aging tolerance. As shown in Table~\ref{table:exp2}, with DCC deployment, the improvement ranges from 7.38\% to 49.77\% and is 24.95\% on average; with high-$V_{th}$ assignment applied on top of DCC deployment, we can achieve better improvement, ranging from 13.97\% to 65.97\% and being 37.61\% on average. The count of inserted DCCs is between 1 (for benchmark \textit{s13207} and \textit{netcard}) to 35 (for benchmark \textit{des\_perf}). The inserted DCC count only has the small proportion of the total buffer count (e.g., at most 3.4\%($= 13/376$) for \textit{s38417}), implying very limited degree of circuit modification and insignificant design overhead. 

\subsection{Discussion: DCC Redeployment due to High-$V_{th}$ Assignment for Clock Buffers}
As we can see, the DCC counts in Column 9 are different from those in Column 5. It implies that DCCs are redeployed in the clock tree while high-$V_{th}$ assignment is incorporated in the framework. To be specific, certain buffers are not allowed to be inserted DCCs at their inputs, due to the violation of timing constraints util high-$V_{th}$ assignment for clock buffers is employed.

For instance, given a clock path $P_{clk}$, a clock buffer $B$ existing along $P_{clk}$, and an associated critical path $P_{critical}$ of $P_{clk}$. Buffer $B$ is not allowed to be inserted any DCC at its input, because the resulting DCC deployment will violate the timing constraints of $P_{critical}$ (i.e., Equation~(\ref{eq:tsu}) and (\ref{eq:th}) are not met). However, when one buffer along $P_{clk}$ is selected as a high-$V_{th}$ buffer leader, buffer $B$ becomes allowed to be inserted certain DCCs at its input, because timing constraints of $P_{critical}$ become met. In short, some clock buffers will become allowed to be inserted at their inputs if high-$V_{th}$ assignment is employed, accounting for the phenomenon of DCC redeployment, as observed in Column 5 and Column 9 in Table~\ref{table:exp2}.

\subsection{Discussion: Increase in Runtime}
When high-$V_{th}$ assignment for clock buffers is applied on top of DCC deployment, the runtime increases because the exploration space of the framework based on useful skews is enlarged. To be specific, given a pair of flip-flops and associated clock paths, we need to consider the various possibilities of leader selection, for each DCC deployment. Therefore, the total count of DCC deployment and leader selection is equal to the combination of DCC deployment plus leader selection, i.e., DCC possibilities multiplied by the leader counterparts, accounting for the increase in runtime. 

Even though the runtime increases while high-$V_{th}$ assignment is incorporated, the resulting framework is still practical for aging tolerance because it at most takes 1370 seconds for a comparative design (e.g., \textit{netcard}).

\subsection{Discussion: Aging Impact on DCCs}
\input{figures/plot_2080dcc_agr}
Figure~\ref{fig:exp4} shows the change in the duty cycle of a 20\%/80\% DCC over 10-year aging. The y axis on the left represents the duty cycle of a 20\% DCC, and the one on the right represents the duty cycle of an 80\% DCC. As it can be seen, the growth in both cases are marginal: $20\% \to 21.07\%$ for a 20\% DCC and $80\% \to 81.35\%$ for an 80\% DCC, which in turn should not affect the benefit of our proposed framework significantly.

\subsection{Discussion: Depth Boundary for DCC Deployment}
\input{figures/plot_boundary}
As mentioned in Section~\ref{sec:framework}, inserting DCCs deep in the clock tree is less effective. For benchmark \textit{des\_perf}, we considered the deployment of DCCs at the upper half of the clock tree (i.e., level 1 to 5) and achieved 38.66\% improvement in terms of aging tolerance. As demonstrated in Figure~\ref{fig:boundary}, if we expand the boundary of DCC deployment from level 1 in the clock tree to level 10 progressively, we can gain a considerable improvement from level 1 to 6; however, from 7 to 10, the improvement become stagnant, but more DCCs are required.

\subsection{Discussion: Convergence of Upper and Lower Bounds of Clock Period during Binary Search}
\input{figures/plot_Tc}
It is worth reminding that, the proposed framework is based on a binary search for optimal clock period $T_{c}$, with initialized upper and lower bounds of $T_{c}$ (see Section~\ref{sec:framework} or Figure~\ref{fig:flow}). From iteration to iteration during binary search, the two bounds of $T_{c}$ converge toward the optimal $T_{c}$. At each iteration, the upper/lower bound can be updated, based on the satisfiability of the SAT problem, which the problem of DCC deployment and leader selection is formulated as.

Figure~\ref{fig:Tc} shows the convergence of the two bounds of $T_{c}$ for benchmark $leo3mp$, during binary search. The X-axis denotes the iteration count of binary search and Y-axis denotes the upper (red line) and lower bounds (blue line) of $T_{c}$. At the first iteration of binary search, the upper bound and lower bound are initialized to 4.24ns and 3ns, respectively. Then, we use the mean value of two bounds (i.e., 3.62ns) to generate the associated CNF clauses based on timing constraints (i.e., inequality Equation~(\ref{eq:tsu}) and (\ref{eq:th})). The CNF clauses are satisfiable from the output of SAT solver, implying that we have the opportunity to explore more lower clock period (i.e., better aging tolerance) by updating the upper bound of $T_{c}$ from 4.24ns to 3.62ns. Then, at the second iteration, we use the mean value of two bounds (i.e., 3.31ns) to generate associated CNF clauses, which are unsatisfiable from the output of SAT solver. It implies that the clock period 3.31ns is too low to find a SAT solution (i.e., there exists no DCC deployment and leader selection to fit the clock period), so that we update the lower bound of $T_{c}$ to 3.31ns. In this manner, the upper and lower bounds of $T_{c}$ will converge toward 3.4061ns. The convergent value of 3.4061ns is the optimal clock period for aging tolerance.

As observed in Figure~\ref{fig:Tc}, we totally use 14 iterations of binary search to reach the convergent value of $T_{c}$, with the accuracy of third digit below the decimal point. If we degrade the accuracy from the third digit to the second digit, we only need 8 iterations. In this manner, we can nearly save half of the runtime. 

\subsection{Discussion: Clause Count Variations during Binary Search}
\input{figures/plot_clause}
From iteration to iteration during binary search, we generate associated CNF clauses based on timing constraints, i.e., inequality Equation~(\ref{eq:tsu}) and (\ref{eq:th}).  As the two bounds of $T_{c}$ converge during binary search, the clause count changes because $T_{c}$ is a variable in Equation~(\ref{eq:tsu}) and (\ref{eq:th}). 

Figure~\ref{fig:Cl} plots the clause count and the runtime of SAT solver in each iteration of binary search, for benchmark $leo3mp$. The X-axis, left Y-axis and right Y-axis denote the iteration count of binary search, CNF clause count and runtime of SAT solver, respectively. The clause count depends on the mean value of two bounds of $T_{c}$. If the mean value is too low/high, more/less possibilities of DCC insertion and leader selection will violate the timing constraints, resulting in more/less associated CNF clauses. For instance, at the second iteration of binary search, the mean value of two bounds is low (3.31ns, see Figure~\ref{fig:Tc}), resulting in large clause count (312798 clauses, see Figure~\ref{fig:Cl}). Thanks to the SAT solver such as MiniSat, we can efficiently solve the SAT problem, which is formulated as CNF clauses, at the cost of less than 10s in each iteration (at most 5.31s for benchmark $leo3mp$).


%In each iteration of binary search, we generate associated CNF clauses based on timing constraints (Section~\ref{sec:VTA:timing}), according to the mean value of two bounds of $T_{c}$. Since the values of two bounds vary in each iteration, the count of CNF clauses changes. Figure~\ref{fig:Cl} plots the clause count in each iteration of binary search, for benchmark $leo3mp$. The clause count strongly depends on the mean value of two bounds of $T_{c}$. If the mean value is too low/high, more/less DCC deployment and more/less leader selection will violate the timing constraints, resulting in more/less associated CNF clauses. For instance, in the 2\textsuperscript{nd} iteration of binary search for benchmark $leo3mp$, the mean value of two bounds is low (3.31ns, see Figure~\ref{fig:Tc}), resulting in large clause count (312798 clauses, see Figure~\ref{fig:Cl}). Thanks to the SAT solver such as MiniSat, we can efficiently solve the SAT problem, at the cost of less than 10s in each iteration.






